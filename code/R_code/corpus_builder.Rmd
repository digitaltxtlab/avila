---
title: "R Corpus Builder"
author: "Isa Lykke Hansen"
date: "6/7/2017"
output: html_document
---

This document is ment for creating a clean corpus containing all the avila texts and the metadata partaining to these

##Setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(pacman)
p_load(tm,SnowballC,tools) #loading packages to be used
wd = "~/Dropbox/IMC/Avila"; #insert path to Avila folder
setwd(wd) #set the working directory to be the Avila folder

```

##Import data
```{r}

books.cor  <- VCorpus(DirSource(paste(wd,"/data/plain_data", sep=''), encoding = "UTF-8"), readerControl = list(language = "lat")) #import all texts in the plain data folder to a SimpleCorpus

```

##Add metadata

In the csv file the following acromyms are used in the "format" column:

tes= spiritual testimonies
sol=soliloquies
minor= minor works

```{r}
meta <- read.csv(paste(wd,"/data/meta_data/metadata.csv", sep=''),sep = ";") #import the metadata

filenames <- file_path_sans_ext(names(books.cor)) #extract the filenames without the ending

# add all the external metadata at document level

for (i in 1:length(books.cor)){
  books.cor[[i]]$meta$document_no <- as.character(meta$document_no[[i]])
  books.cor[[i]]$meta$name <- as.character(meta$name[[i]])
  books.cor[[i]]$meta$format <- as.character(meta$format[[i]])
  books.cor[[i]]$meta$year <- as.character(meta$year[[i]])
  books.cor[[i]]$meta$month <- as.character(meta$month[[i]])
  books.cor[[i]]$meta$day <- as.character(meta$day[[i]])
  books.cor[[i]]$meta$sender_city <- as.character(meta$sendercity[[i]])
  books.cor[[i]]$meta$reciever <- as.character(meta$narecieverme[[i]])
  books.cor[[i]]$meta$reciever_city <- as.character(meta$reciever_city[[i]])
  books.cor[[i]]$meta$incomplete <- as.character(meta$incomplete[[i]])
  books.cor[[i]]$meta$no_chapters <- as.character(meta$no_chapters[[i]])
  books.cor[[i]]$meta$book <- as.character(meta$book[[i]])
  books.cor[[i]]$meta$notes <- as.character(meta$notes[[i]])
  books.cor[[i]]$meta$translator <- as.character(meta$translator[[i]])
  books.cor[[i]]$meta$filename <- as.character(filenames[[i]])
}

```

##Clean data
```{r}

stop.words = as.character(read.table(paste(wd,"/data/stopword_us.txt",sep=''))[,1]) #import our own, more elaborate list of words to be removed from the text

# clean corpus
clean_corpus <- function(corpus){
  #main <- tm_map(books.cor, PlainTextDocument) #is this important? - because it removes the metadata
  main <- tm_map(books.cor, content_transformer(tolower))
  main <- tm_map(main, removePunctuation)
  main <- tm_map(main, removeNumbers)
  main <- tm_map(main, removeWords, stop.words) #alternatively, use: stopwords("english")
  main <- tm_map(main, stemDocument)
  main <- tm_map(main, stripWhitespace)
  return(main)
}

clean.corpus <- clean_corpus(books.cor) #return the cleaned corpus

```
